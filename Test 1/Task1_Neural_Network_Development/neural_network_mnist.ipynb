{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2OyiqFcJRQsoD/5NXzNo+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"id":"jeHGonhk-qym","executionInfo":{"status":"ok","timestamp":1701716042413,"user_tz":-360,"elapsed":17,"user":{"displayName":"SS Dip","userId":"05047776113731340581"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten"]},{"cell_type":"code","source":["# Load the MNIST dataset\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHpiYrLRLR2L","executionInfo":{"status":"ok","timestamp":1701716051004,"user_tz":-360,"elapsed":2268,"user":{"displayName":"SS Dip","userId":"05047776113731340581"}},"outputId":"1ce02978-eaf6-422c-b9cc-3c2fa38a2cba"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["# Normalize pixel values to be between 0 and 1\n","x_train, x_test = x_train / 255.0, x_test / 255.0"],"metadata":{"id":"PmSrZeGiLjZS","executionInfo":{"status":"ok","timestamp":1701716055128,"user_tz":-360,"elapsed":576,"user":{"displayName":"SS Dip","userId":"05047776113731340581"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Create a simple neural network model\n","model = Sequential([\n","    Flatten(input_shape=(28, 28)),  # Flatten the 28x28 images into a 1D array\n","    Dense(128, activation='relu'),  # Hidden layer with 128 neurons and ReLU activation\n","    Dense(10, activation='softmax')  # Output layer with 10 neurons for 10 classes and softmax activation\n","])"],"metadata":{"id":"FQkRUMSOLkuj","executionInfo":{"status":"ok","timestamp":1701716062771,"user_tz":-360,"elapsed":681,"user":{"displayName":"SS Dip","userId":"05047776113731340581"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Compile the model\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"id":"vE_wkVNfLmtj","executionInfo":{"status":"ok","timestamp":1701716071118,"user_tz":-360,"elapsed":576,"user":{"displayName":"SS Dip","userId":"05047776113731340581"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","history = model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9kZ4acBkLokr","executionInfo":{"status":"ok","timestamp":1701716120151,"user_tz":-360,"elapsed":42510,"user":{"displayName":"SS Dip","userId":"05047776113731340581"}},"outputId":"39b7e602-7e45-405c-edd7-ff927461d781"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1875/1875 [==============================] - 10s 5ms/step - loss: 0.2669 - accuracy: 0.9237 - val_loss: 0.1410 - val_accuracy: 0.9589\n","Epoch 2/5\n","1875/1875 [==============================] - 8s 4ms/step - loss: 0.1164 - accuracy: 0.9663 - val_loss: 0.0965 - val_accuracy: 0.9704\n","Epoch 3/5\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0807 - accuracy: 0.9754 - val_loss: 0.0842 - val_accuracy: 0.9733\n","Epoch 4/5\n","1875/1875 [==============================] - 9s 5ms/step - loss: 0.0599 - accuracy: 0.9816 - val_loss: 0.0773 - val_accuracy: 0.9764\n","Epoch 5/5\n","1875/1875 [==============================] - 7s 4ms/step - loss: 0.0461 - accuracy: 0.9857 - val_loss: 0.0726 - val_accuracy: 0.9780\n"]}]},{"cell_type":"code","source":["# Evaluate the model\n","test_loss, test_acc = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aG1o8peALqdl","executionInfo":{"status":"ok","timestamp":1701716194977,"user_tz":-360,"elapsed":22,"user":{"displayName":"SS Dip","userId":"05047776113731340581"}},"outputId":"8f31e25b-b391-4226-fb0f-96ee9cb49488"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 2ms/step - loss: 0.0726 - accuracy: 0.9780\n"]}]},{"cell_type":"code","source":["print(f\"Test accuracy: {test_acc}\")\n","print(f\"Test loss: {test_loss}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bnhUnlJ6Ls13","executionInfo":{"status":"ok","timestamp":1701716199738,"user_tz":-360,"elapsed":582,"user":{"displayName":"SS Dip","userId":"05047776113731340581"}},"outputId":"8305bcdc-6c55-4fdf-fbe5-a42730673173"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Test accuracy: 0.9779999852180481\n","Test loss: 0.0726369097828865\n"]}]},{"cell_type":"markdown","source":["Explanation:\n","\n","1. ***Loading and Preprocessing Data***: The MNIST dataset containing handwritten digits is loaded using mnist.load_data(). The pixel values are normalized to be between 0 and 1 by dividing by 255.\n","\n","2. ***Creating the Model***: A Sequential model is used where layers are added one after another. Flatten layer flattens the input images. Two Dense layers are added, one hidden layer with 128 neurons and ReLU activation, and an output layer with 10 neurons (since there are 10 classes in MNIST) and softmax activation.\n","\n","3. ***Compiling the Model***: The model is compiled using the Adam optimizer, sparse categorical cross-entropy loss (suitable for integer-encoded class labels), and accuracy as the metric to monitor during training.\n","\n","4. ***Training the Model***: The model is trained using model.fit() on the training data (x_train and y_train) for 5 epochs with validation data provided.\n","\n","5. ***Evaluation***: The model is evaluated on the test data (x_test and y_test) using model.evaluate() to obtain the test accuracy and loss.\n","\n","Adjusting parameters such as the number of layers, neurons, activation functions, optimizer, epochs, batch size, etc., might improve the model's performance. However, this example provides a basic structure to get started with MNIST classification using a neural network."],"metadata":{"id":"VHbYUEePMOFM"}}]}